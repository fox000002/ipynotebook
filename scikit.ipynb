{
 "metadata": {
  "name": "scikit"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(__doc__)\n",
      "\n",
      "from sklearn import svm\n",
      "from sklearn.datasets import samples_generator\n",
      "from sklearn.feature_selection import SelectKBest, f_regression\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "# import some data to play with\n",
      "X, y = samples_generator.make_classification(\n",
      "    n_features=20, n_informative=3, n_redundant=0, n_classes=4,\n",
      "    n_clusters_per_class=2)\n",
      "\n",
      "# ANOVA SVM-C\n",
      "# 1) anova filter, take 3 best ranked features\n",
      "anova_filter = SelectKBest(f_regression, k=3)\n",
      "# 2) svm\n",
      "clf = svm.SVC(kernel='linear')\n",
      "\n",
      "anova_svm = make_pipeline(anova_filter, clf)\n",
      "anova_svm.fit(X, y)\n",
      "anova_svm.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Built-in functions, exceptions, and other objects.\n",
        "\n",
        "Noteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "array([1, 3, 0, 1, 3, 3, 0, 2, 1, 1, 0, 1, 2, 0, 0, 3, 0, 0, 0, 2, 1, 1, 3,\n",
        "       3, 3, 2, 1, 0, 3, 2, 3, 0, 3, 3, 2, 2, 3, 2, 3, 2, 1, 2, 2, 2, 2, 3,\n",
        "       2, 2, 0, 2, 3, 1, 1, 2, 3, 0, 2, 3, 0, 2, 0, 3, 1, 0, 0, 3, 3, 3, 0,\n",
        "       1, 3, 1, 3, 3, 3, 1, 1, 3, 0, 1, 2, 0, 0, 1, 2, 3, 3, 0, 0, 1, 2, 1,\n",
        "       1, 2, 1, 0, 2, 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "iris = datasets.load_iris()\n",
      "X_iris, y_iris = iris.data, iris.target\n",
      "print X_iris.shape, y_iris.shape\n",
      "print X_iris[0], y_iris[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(150L, 4L) (150L,)\n",
        "[ 5.1  3.5  1.4  0.2] 0\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(__doc__)\n",
      "\n",
      "# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n",
      "# License: BSD 3 clause\n",
      "\n",
      "# Standard scientific Python imports\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Import datasets, classifiers and performance metrics\n",
      "from sklearn import datasets, svm, metrics\n",
      "\n",
      "# The digits dataset\n",
      "digits = datasets.load_digits()\n",
      "\n",
      "# The data that we are interested in is made of 8x8 images of digits, let's\n",
      "# have a look at the first 3 images, stored in the `images` attribute of the\n",
      "# dataset.  If we were working from image files, we could load them using\n",
      "# pylab.imread.  Note that each image must have the same size. For these\n",
      "# images, we know which digit they represent: it is given in the 'target' of\n",
      "# the dataset.\n",
      "images_and_labels = list(zip(digits.images, digits.target))\n",
      "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
      "    plt.subplot(2, 4, index + 1)\n",
      "    plt.axis('off')\n",
      "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
      "    plt.title('Training: %i' % label)\n",
      "\n",
      "# To apply a classifier on this data, we need to flatten the image, to\n",
      "# turn the data in a (samples, feature) matrix:\n",
      "n_samples = len(digits.images)\n",
      "data = digits.images.reshape((n_samples, -1))\n",
      "\n",
      "# Create a classifier: a support vector classifier\n",
      "classifier = svm.SVC(gamma=0.001)\n",
      "\n",
      "# We learn the digits on the first half of the digits\n",
      "classifier.fit(data[:n_samples / 2], digits.target[:n_samples / 2])\n",
      "\n",
      "# Now predict the value of the digit on the second half:\n",
      "expected = digits.target[n_samples / 2:]\n",
      "predicted = classifier.predict(data[n_samples / 2:])\n",
      "\n",
      "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
      "      % (classifier, metrics.classification_report(expected, predicted)))\n",
      "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
      "\n",
      "images_and_predictions = list(zip(digits.images[n_samples / 2:], predicted))\n",
      "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
      "    plt.subplot(2, 4, index + 5)\n",
      "    plt.axis('off')\n",
      "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
      "    plt.title('Prediction: %i' % prediction)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Built-in functions, exceptions, and other objects.\n",
        "\n",
        "Noteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\n",
        "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
        "  gamma=0.001, kernel='rbf', max_iter=-1, probability=False,\n",
        "  random_state=None, shrinking=True, tol=0.001, verbose=False):\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       1.00      0.99      0.99        88\n",
        "          1       0.99      0.97      0.98        91\n",
        "          2       0.99      0.99      0.99        86\n",
        "          3       0.98      0.87      0.92        91\n",
        "          4       0.99      0.96      0.97        92\n",
        "          5       0.95      0.97      0.96        91\n",
        "          6       0.99      0.99      0.99        91\n",
        "          7       0.96      0.99      0.97        89\n",
        "          8       0.94      1.00      0.97        88\n",
        "          9       0.93      0.98      0.95        92\n",
        "\n",
        "avg / total       0.97      0.97      0.97       899\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Confusion matrix:\n",
        "[[87  0  0  0  1  0  0  0  0  0]\n",
        " [ 0 88  1  0  0  0  0  0  1  1]\n",
        " [ 0  0 85  1  0  0  0  0  0  0]\n",
        " [ 0  0  0 79  0  3  0  4  5  0]\n",
        " [ 0  0  0  0 88  0  0  0  0  4]\n",
        " [ 0  0  0  0  0 88  1  0  0  2]\n",
        " [ 0  1  0  0  0  0 90  0  0  0]\n",
        " [ 0  0  0  0  0  1  0 88  0  0]\n",
        " [ 0  0  0  0  0  0  0  0 88  0]\n",
        " [ 0  0  0  1  0  1  0  0  0 90]]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(__doc__)\n",
      "\n",
      "# Author: Alexandre Gramfort <alexandre.gramfort@inria.fr>\n",
      "# License: BSD 3 clause\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC\n",
      "from sklearn import datasets\n",
      "\n",
      "iris = datasets.load_iris()\n",
      "X = iris.data[:, 0:2]  # we only take the first two features for visualization\n",
      "y = iris.target\n",
      "\n",
      "n_features = X.shape[1]\n",
      "\n",
      "C = 1.0\n",
      "\n",
      "# Create different classifiers. The logistic regression cannot do\n",
      "# multiclass out of the box.\n",
      "classifiers = {'L1 logistic': LogisticRegression(C=C, penalty='l1'),\n",
      "               'L2 logistic': LogisticRegression(C=C, penalty='l2'),\n",
      "               'Linear SVC': SVC(kernel='linear', C=C, probability=True,\n",
      "                                 random_state=0)}\n",
      "\n",
      "n_classifiers = len(classifiers)\n",
      "\n",
      "plt.figure(figsize=(3 * 2, n_classifiers * 2))\n",
      "plt.subplots_adjust(bottom=.2, top=.95)\n",
      "\n",
      "for index, (name, classifier) in enumerate(classifiers.items()):\n",
      "    classifier.fit(X, y)\n",
      "\n",
      "    y_pred = classifier.predict(X)\n",
      "    classif_rate = np.mean(y_pred.ravel() == y.ravel()) * 100\n",
      "    print(\"classif_rate for %s : %f \" % (name, classif_rate))\n",
      "\n",
      "    # View probabilities=\n",
      "    xx = np.linspace(3, 9, 100)\n",
      "    yy = np.linspace(1, 5, 100).T\n",
      "    xx, yy = np.meshgrid(xx, yy)\n",
      "    Xfull = np.c_[xx.ravel(), yy.ravel()]\n",
      "    probas = classifier.predict_proba(Xfull)\n",
      "    n_classes = np.unique(y_pred).size\n",
      "    for k in range(n_classes):\n",
      "        plt.subplot(n_classifiers, n_classes, index * n_classes + k + 1)\n",
      "        plt.title(\"Class %d\" % k)\n",
      "        if k == 0:\n",
      "            plt.ylabel(name)\n",
      "        imshow_handle = plt.imshow(probas[:, k].reshape((100, 100)),\n",
      "                                   extent=(3, 9, 1, 5), origin='lower')\n",
      "        plt.xticks(())\n",
      "        plt.yticks(())\n",
      "        idx = (y_pred == k)\n",
      "        if idx.any():\n",
      "            plt.scatter(X[idx, 0], X[idx, 1], marker='o', c='k')\n",
      "\n",
      "ax = plt.axes([0.15, 0.04, 0.7, 0.05])\n",
      "plt.title(\"Probability\")\n",
      "plt.colorbar(imshow_handle, cax=ax, orientation='horizontal')\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Built-in functions, exceptions, and other objects.\n",
        "\n",
        "Noteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\n",
        "classif_rate for Linear SVC : 82.000000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classif_rate for L1 logistic : 79.333333 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classif_rate for L2 logistic : 76.666667 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}